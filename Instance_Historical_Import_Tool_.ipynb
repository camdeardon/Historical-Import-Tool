{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kzM1Yq2-CNi6",
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "The code below is a script example of a tool that is used will query an instance take records using the knowledge map API to create a data import record for use in instance consolidation or quickly grabbing data from one instance to put into another. \n",
    "\n",
    "This script will also work to fill out an Edcast import CSV and leverage the Axonify APIs to create Deeplinks in the Topic Sync function.\n",
    "\n",
    "This code will import the libraries that are required to run this script and store the records on your machine in a folder call \"Edcast_Axonify_connection\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gUqhXOe6EMXu",
    "tags": []
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --user -U nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xf8roFvaOCJd"
   },
   "outputs": [],
   "source": [
    "# Data manipulation libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# API calling libraries\n",
    "import json\n",
    "from datetime import datetime\n",
    "import requests\n",
    "from tqdm import tqdm, trange\n",
    "\n",
    "\n",
    "# Libraries to save files\n",
    "import os\n",
    "from os import path\n",
    "import getpass\n",
    "\n",
    "\n",
    "\n",
    "# Natural Language processing libraries\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f5xfrzdCEQZN"
   },
   "source": [
    "## Provide a list of users with of the learning records you'd like to retrieve. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The script will iterate through the users, calling the GET knowledgeMap API to retrieve the data for each user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 74
    },
    "id": "mNHSYgBpa0R7",
    "outputId": "1bc7a47a-810f-47f1-a8e6-737e3a76a620"
   },
   "outputs": [],
   "source": [
    "# Provide a list of users with of the learning records you'd like to retrieve. \n",
    "users = ['']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0vUBKA3UEfiB",
    "tags": []
   },
   "source": [
    "## Get topic_sync function is created"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oRUtb5EZA5cf"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "This function will make the files, and create a folder within the folder \"Edcast_Axonify_connection, that now should be created on your desktop, containing the name of the instance. It will fill in the CSV provided by Edcast\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9hpHRaibOLTu"
   },
   "outputs": [],
   "source": [
    "# This grabs the time and saves it as a string for use later on.\n",
    "today = datetime.now().strftime(\"%Y%m%d\")\n",
    "folder_today = datetime.now().strftime('%d - %B - %Y')\n",
    "today_seconds = datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
    "username = getpass.getuser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sr-U5A5tE30L"
   },
   "outputs": [],
   "source": [
    "# This text will extract topic names, and remove stopwords for use in extracting key words\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def remove_stop_words(text):\n",
    "    tokens = word_tokenize(text)\n",
    "    filtered_tokens = [token for token in tokens if not token.lower() in stop_words]\n",
    "    filtered_text = ' '.join(filtered_tokens)\n",
    "    return filtered_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UkmE6jklRNdY"
   },
   "outputs": [],
   "source": [
    "def topic_sync(instance,users,api_key,date):\n",
    "    #Create empty lists to store user data in.\n",
    "    topic_data = []\n",
    "    subject_data = []\n",
    "    category_data = []\n",
    "    intro_data = []\n",
    "    not_found_users = []\n",
    "\n",
    "    \n",
    "    # This will check to see if you have a folder for the particular instance, and if you do not it will create one.\n",
    "    instance_path = f'/Users/{username}/Desktop/Edcast_Axonify_connection/{folder_today}/{instance}'\n",
    "    if not os.path.exists(instance_path):\n",
    "        \n",
    "        # create the folder for storing the CSV records\n",
    "        os.makedirs(instance_path)\n",
    "        print(f'Folder {instance_path} created.')\n",
    "    else:\n",
    "        print(f'Folder {instance_path} already exists.')\n",
    "\n",
    "\n",
    "    # iterate through users and grab the knowledge map using the Knowledge Map API\n",
    "    # In order to use the API the data needs to be parsed from the response. \n",
    "    \n",
    "    for user in tqdm(users,desc = 'Record Calls', unit = 'User Knowledge Maps Receieved'):\n",
    "        try:\n",
    "            # Call the knowledgemap API calling in the variables for user, instance and provide an API token.\n",
    "            knowledge_map = f\"https://{instance}/axonify/api/v2/users/{user}/knowledgemap?api_token={api_key}\"\n",
    "            knowledge_map_data = requests.get(knowledge_map).json()\n",
    "            \n",
    "            # Split the response into the API into the employeeId and knowledgeRecords\n",
    "            employeeId = knowledge_map_data['employeeId']\n",
    "            knowledgeRecords = knowledge_map_data['knowledgeRecords']\n",
    "            \n",
    "            # Optional, this will print out for logging purposes.\n",
    "            #print(f'EmployeeID: {user} Knowledge Map Retrieved')\n",
    "            \n",
    "\n",
    "        # iterate through the knowledgeRecords, collecting the data for each record.\n",
    "        \n",
    "            for record in knowledgeRecords:\n",
    "                # extract the values for topicExternalId, level, topicGraduationTimestamp, totalAnswerCount and correctAnswerCount\n",
    "                categoryExternalId = record['topicDetails']['categoryExternalId']\n",
    "                categoryName = record['topicDetails']['categoryName']    \n",
    "                topicExternalId = record['topicDetails']['topicExternalId']\n",
    "                topicName = record['topicDetails']['topicName']\n",
    "                subjectExternalId = record['topicDetails']['subjectExternalId']\n",
    "                topicInternalId = record['topicDetails']['topicId']\n",
    "                subjectName = record['topicDetails']['subjectName']\n",
    "                level = record['topicDetails']['level']\n",
    "                topicGraduationTimestamp = record['topicGraduationTimestamp']\n",
    "                correctAnswerCount = record['overallMetrics']['correctAnswerCount']\n",
    "                totalAnswerCount = record['overallMetrics']['totalAnswerCount']\n",
    "                introductoryStatus = record['introductoryStatus']\n",
    "                \n",
    "                # Add records to the topic data array\n",
    "                topic_data.append([employeeId, topicExternalId,topicName, level,topicInternalId ])\n",
    "             \n",
    "        except:\n",
    "            not_found_users.append(user)\n",
    "            pass\n",
    "            #print(f'User {user} not found')\n",
    "            #not_found_users.append(user)\n",
    "\n",
    "    # Create a dataframe from the data lists with the columns of 'Employee_ID', 'Topic_External_ID', 'Topic_Name','Difficulty_Level','Internal_Id'\n",
    "    \n",
    "    # This data can now be parsed to create deep links into individual topics.\n",
    "    # This function exports this dataframe as a csv\n",
    "    \n",
    "    topic_df = pd.DataFrame(topic_data, columns=['Employee_ID', 'Topic_External_ID', 'Topic_Name','Difficulty_Level','Internal_Id'])\n",
    "\n",
    "\n",
    "    # Ed_Cast Template. This code will provide deep links to topics.\n",
    "    # Deep link base URL\n",
    "    base_url = f'https://{instance}/training/index.html#assessmentLink?topicId='\n",
    "    \n",
    "    # Use the difficulty level, topic internal id in conjunction with the base URL to create topic deep links.\n",
    "    topic_df['Topic_Deep_Link'] = topic_df.apply(lambda row: base_url + str(row['Internal_Id']) + '&level=' + str(row['Difficulty_Level']), axis=1)\n",
    "    \n",
    "    ed_cast_template = topic_df[['Topic_External_ID','Topic_Name','Topic_Deep_Link','Difficulty_Level']]\n",
    "    \n",
    "    ed_cast_template['description'] = \"\"\n",
    "    ed_cast_template['image_url'] = \"\"\n",
    "    ed_cast_template['Topic_Name'] = ed_cast_template['Topic_Name'].apply(remove_stop_words)\n",
    "    ed_cast_template['keywords'] = topic_df['Topic_Name'].str.replace(\" \",\",\")\n",
    "    ed_cast_template['duration'] = \"\"\n",
    "    ed_cast_template['archive'] = \"\"\n",
    "    ed_cast_template['language'] = 'en'\n",
    "    ed_cast_template['content_type'] = \"course\"\n",
    "    ed_cast_template['providor_name'] = 'Axonify'\n",
    "\n",
    "    # Rename the columns to match the requirements for Edcast.\n",
    "    ed_cast_template = ed_cast_template.rename(columns = {'Topic_External_Id':'id','Topic_Name':'title','Topic_Deep_Link':'deeplink_url'})\n",
    "    ed_cast_template['Topic_Name'] = ed_cast_template.apply(lambda row: row['title'] + ' - Level ' + str(row['Difficulty_Level']), axis=1)\n",
    "    ed_cast_template['title'] = ed_cast_template['Topic_Name']\n",
    "    ed_cast_template = ed_cast_template.drop(columns = ['Topic_Name','Difficulty_Level'])\n",
    "    \n",
    "\n",
    "    # Export the dataframes to a CSV file\n",
    "    ed_cast_template.to_csv(f'{instance_path}/{instance}_Edcast_Template_{today_seconds}.csv',index = False)\n",
    "    topic_df.to_csv(f'{instance_path}/{instance}_Assigned_Knowledge_Map_{today_seconds}.csv',index = False)\n",
    "\n",
    "    return ed_cast_template, topic_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MC1__OwCEVVJ"
   },
   "source": [
    "# Pass in API Key / Instance URL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BSKsoiv6AvJp"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "This code is where you can specific your API key and your instance name. Change the strings below to the relavent information, taking care to keep the information between quotation marks like below. \n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cYNaSIvuDPVU",
    "outputId": "1bce0bfd-7281-464b-d597-68bb60be3d53"
   },
   "outputs": [],
   "source": [
    "instance = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HGbGY9HFDEVq",
    "outputId": "9040c8f5-ddfd-4b42-d01f-a8e644baf5b1"
   },
   "outputs": [],
   "source": [
    "api_token = ''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cemqqcOhElCH"
   },
   "source": [
    "# Get knowledge records function is called"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AlMQ3GquBOGp"
   },
   "source": [
    "\n",
    "---\n",
    "\n",
    "\n",
    "This code below will call the function with your input variables.\n",
    "\n",
    "---\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-cbBYQObOQMx"
   },
   "outputs": [],
   "source": [
    "records = topic_sync(instance,users,api_token,today_seconds)"
   ]
  }
